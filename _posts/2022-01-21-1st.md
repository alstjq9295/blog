---
layout: default
title: "2022 1Q 스터디 목표"
description: "MBTI 관련 인스타그램 데이터 기반 서비스 만들기"
tags: [Blog]
date: 2022-01-21
last_modified_at: 2022-01-21
---
```
* 2022 1Q DMK Study
    - MBTI 관련 인스타그램 데이터 기반 서비스 만들기
```
# 2022 1Q 스터디 목표

## Python selenium 을 이용한 크롤링 겉핥기
- Python selenium 을 이용한 인스타그램 수집기 이해

## RDB 스키마 모델링
- Buzz 랑 비슷하다 하니 패스

## ElasticSearch 인덱스 모델링
- 흠터레스팅
- ES Index Template 설정
    - 필드별 타입 설정
    - 일별? 월별? 연도별?
- ES 자체 자연어처리 머신러닝 사용 가능?

## Machine Learning
**Clustering 알고리즘 핥짝**
- K-Means Clustering
    - 장점:
        1. 분류 알고리즘 중 비교적 쉽고 빠르게 모델링 및 적용이 가능하다.
        2. 대용량 데이터에 적합하다.
    - 단점:
        1. k, centeroid 값을 임의로 설정해야 한다.
        2. 이상치(Outlier) 에 민감하며 제외하지 못한다.
        3. 원형 클러스터링의 한계가 있다.

- Gaussian Mixture Models (GMM)
    - 장점:
        1. 기하학적 형태의 군집도 분류 가능하다.
    - 단점:
        1. K-Means 와 마찬가지로 군집 수를 설정해야 한다.
        2. Mixture 모델의 속도 한계가 있다.

- Density-Based Spatial Clustering of Applications with Noise (DBSCAN)
    - 장점:
        1. 군집 수를 설정할 필요가 없다.
        2. 노이즈 분류가 가능하다.
        3. 군집 형태에 크게 제한받지 않는다.
    - 단점:
        1. 하이퍼 파라미터를 설정하기 까다롭다.
        2. 고차원 데이터 분류에 한계가 있다.
        3. 학습 데이터 순서에 따라 분류 결과에 차이가 크다.

**Classification 알고리즘 핥짝**
- Random Forest
    - 장점:
        1. 학습 속도가 비교적 빠르다.
        2. 데이터 스케일링이 필수적이지 않다.
        3. 결측치에 대해 유연하며 과적합이 잘 일어나지 않는다.
    - 단점:
        1. 메모리 소모가 크다.
        2. 일정량을 넘어가면 학습 데이터를 증가시켜도 정확도 향상의 폭이 크지 않다.
        3. 텍스트 또는 고차원 데이터에 적합하지 않다.

- Support Vector Machine
    - 장점:
        1. 학습 데이터가 많지 않아도 비교적 좋은 정확도의 모델 구축이 가능하다.
        2. 과적합이 잘 일어나지 않는다.
    - 단점:
        1. 학습 속도가 비교적 느리다.
        2. 파라미터 설정에 민감하다.

- XGBoost(eXtreme Gradient Boosting)
    - 장점:
        1. 분류와 회귀 모두 사용가능하며 GBM 대비 빠르다.
        2. 과적합 방지, 교차 검증 등 다양한 자체 기능을 제공한다.
    - 단점:
        1. 하이퍼 파라미터에 민감하고 설정이 어렵다.
        2. 모델 구축에 오랜 시간이 걸린다.

## 웹/앱 서비스
- 웹은 핥짝
- 앱은...할 수 있을까..?
