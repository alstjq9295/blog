---
layout: default
title: "ElasticSearch tiny tips"
description: "MBTI 관련 인스타그램 데이터 기반 서비스 만들기"
categories:
    - Blog
tags:
    - Blog
date: 2022-02-10
last_modified_at: 2022-02-10
---
```
* 2022 1Q DMK Study
    - MBTI 관련 인스타그램 데이터 기반 서비스 만들기
```
# ElasticSearch tiny tips

### [Hot/Warm]-Data Node
- Hot-Data Node 는 빠른 색인을 위해 SSD 사용 권고
- Warm-Data Node 는 상대적으로 저렴하고 고용량인 HDD 지향
- 최근 데이터 주기를 정하여 시간이 지난 인덱스의 샤드를 Warm-Data Node 로 재할당하는 방식
- 설정 방법 예시)
    ```text
  $ sudo vi /etc/elasticsearch/elasticsearch.yml
  
  # hotdata node setting
  node.attr.box_type: hot
  # warmdata node setting
  node.attr.box_type: warm
    ```

### 모든 인덱스에 대해 _all 이나 wildcard 를 대상으로 삭제작업 방지하기
- 인덱스가 정의될 위치에 _all 을 넣거나 wildcard (*) 를 넣으면 전체 인덱스에 대해 작업 가능
- DELETE 의 경우는 의도되지 않은 실수를 방지하기 위해 해당 작업 disable 가능
- 설정 방법 예시)
    ```text
  PUT _cluster/settings
  {
      "transient": {
        "action.destructive_requires_name": true
      }
  }
    ```

### _open/close API
- 인덱스의 상태를 open/close 할 수 있는 API
- closed 된 인덱스는 read/write 불가
- 클러스터 전체 샤드에서 제외
- 라우팅 disabled
- 설정 방법 예시)
    ```text
  POST {index_name}/_open
  POST {index_name}/_close
    ```

### About Analyzer
- Analyzer는 character filter, tokenizer, token filter 순서대로 적용한다. 기본적으로 anaylyzer는 indexing time과 search time에 적용된다. index time 분석 대상은 source data(원본 데이터)이고 search time 분석 대상은 query string이다. 그러므로 사전을 변경하는 것은 indexing, serching 두개 모두 영항을 준다.
- userdict 를 업데이트하여 적용하려면 노드를 재시작하거나 적용되는 인덱스를 close&open 해줘야 한다. 하지만 이미 적재된 데이터에는 적용되지 않는다. 적용을 원한다면 **reindex** 하는 방법 뿐이다.
- 대소문자 구분없이 analyzer 를 원한다면 analyzer 의 filter 세팅에 "lowercase" 를 추가
    - 예시) 
    ```json
  "analyzer": {
      "nori_analyzer": {
          "tokenizer": "nori_tokenizer",
          "decompound_mode": "mixed",
          "filter": ["lowercase"]
      },
      "whitespace": {
          "tokenizer": "whitespace",
          "filter": ["lowercase"],
          "char_filter": ["my_char_filter"]
      }
  }
    ```
- analyzer 에 텍스트의 매핑을 원한다면 "char_filter" 세팅으로 구현할 수 있다.
    - 예시) ("\\u0020" = 공백)
    ```json
  "analyzer": {
      "whitespace": {
          "tokenizer": "whitespace",
          "filter": ["lowercase"],
          "char_filter": ["my_char_filter"]
      }
  },
  "char_filter": {
      "my_char_filter": {
          "type": "mapping",
          "mappings": [
              ", => \\u0020",
              "| => \\u0020"
          ]
      }
  }
    ```
- 7.12.1 버전에 추가된 유용해 보이는 필드: version, flattenezd
    - 참조 URL: http://kimjmin.net/2021/04/2021-04-advanced-doc-fields/

### Plugin
- elasticsearch-head
    ```text
  ]# cd ~
  ]# mkdir ./rpms/nodejs
  ]# curl -sL https://rpm.nodesource.com/setup_12.x | sudo bash -
  ]# yum install nodejs --downloadonly --downloaddir=./
  "nodejs rpm 파일만 받아지겠지만 npm 실행 잘 됨"
  ]# rpm -Uvh ./rpms/nodejs/nodejs[~].rpm
  
  ]# cd /usr/local "원하는 경로 아무데나"
  ]# git clone git://github.com/mobz/elasticsearch-head.git
  ]# cd elasticsearch-head
  ]# npm install
  ]# npm run start
    ```
- elasticsearch-HQ (Docker)
    ```text
  ]# cd ~
  ]# mkdir ./rpms/docker
  ]# yum install docker --downloadonly --downloaddir=./
  ]# rpm -Uvh ./rpms/docker/[*].rpm
  
  ]# docker run -p 5000:5000 elastichq/elasticsearch-hq > /var/log/docker-elasticsearch-HQ.log &
    ```
    - 해당 Public IP:5000 들어가서 "Found 0 Cluster" 라는 안내문이 뜨면 "Connect to Elasticsearch..." 값을 [http://localhost:9200](http://localhost:9200/) 에서 http://[Private IP]:[Port] 으로 수정해서 기다리면 (난 꽤 오래 걸림) 클러스터를 찾아냄
    - 도커로 구동한 이유는 파이썬을 설치하지 않는 방법이기도 했고 버전도 같이 보여줬고 master-03 에서 git repo 구동이 안돼서....
    - 참고로 로그 파일이나 경로는 각자 원하는 대로 설정하길
    - ** 생각보다 로그가 빨리, 그리고 많이 쌓인다. 별도로 로그를 쌓지 않더라도 /var/log/message 에 쌓이니 로그를 주기적으로 삭제할 크론잡 추가도 필요함 **